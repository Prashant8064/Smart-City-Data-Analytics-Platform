{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# ==============================================================\n",
        "import os, math, random, warnings, argparse\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.inspection import permutation_importance\n",
        "import joblib\n",
        "\n",
        "\n",
        "try:\n",
        "    import gradio as gr\n",
        "    _HAS_GRADIO = True\n",
        "except Exception:\n",
        "    _HAS_GRADIO = False\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "OUTDIR = \"data\"\n",
        "CSV_PATH = os.path.join(OUTDIR, \"pollution.csv\")\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"pollution_model.pkl\")\n",
        "SCALER_PATH = os.path.join(OUTDIR, \"scaler.pkl\")\n",
        "\n",
        "\n",
        "START = datetime(2024, 1, 1)\n",
        "N_DAYS = 30\n",
        "TIMESTEP_MIN = 60\n",
        "CITY_CENTER = (28.6139, 77.2090)\n",
        "RADIUS_KM = 20\n",
        "\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "FEATURES = [\"pm25_lag1\", \"pm25_lag24\", \"hour\", \"dayofweek\", \"lat\", \"lon\"]\n",
        "TARGET = \"pm25\"\n",
        "\n",
        "\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def random_point(center, radius_km):\n",
        "    lat0, lon0 = center\n",
        "    r = radius_km * math.sqrt(random.random())\n",
        "    theta = random.random() * 2 * math.pi\n",
        "    dx = r * math.cos(theta) / 110.574\n",
        "    dy = r * math.sin(theta) / (111.320 * math.cos(math.radians(lat0)))\n",
        "    return lat0 + dx, lon0 + dy"
      ],
      "metadata": {
        "id": "tzoAltt5FI-_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Generate synthetic dataset (if missing)\n",
        "# ==============================================================\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    print(\"Generating synthetic dataset...\")\n",
        "    sensors = []\n",
        "    for i in range(20):\n",
        "        lat, lon = random_point(CITY_CENTER, RADIUS_KM)\n",
        "        sensors.append({\"sensor_id\": f\"S{i+1}\", \"lat\": lat, \"lon\": lon})\n",
        "    sensors = pd.DataFrame(sensors)\n",
        "\n",
        "\n",
        "    rows = []\n",
        "    for day in range(N_DAYS):\n",
        "        for t in range(0, 24*60, TIMESTEP_MIN):\n",
        "            ts = START + timedelta(days=day, minutes=t)\n",
        "            hour = ts.hour\n",
        "            base_pm = 40 + 20*math.sin((hour/24.0)*2*math.pi)\n",
        "            for _, s in sensors.iterrows():\n",
        "                pm = max(5, np.random.normal(base_pm + random.uniform(-5,5), 8))\n",
        "                rows.append({\"timestamp\": ts, \"sensor_id\": s.sensor_id,\n",
        "                             \"lat\": s.lat, \"lon\": s.lon, \"pm25\": round(pm,2)})\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(CSV_PATH, index=False)\n",
        "    print(f\"Synthetic data saved to {CSV_PATH}\")\n",
        "else:\n",
        "    df = pd.read_csv(CSV_PATH, parse_dates=[\"timestamp\"])\n",
        "    print(f\"Loaded existing dataset from {CSV_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn9Bt6_cFouH",
        "outputId": "465edd0f-37f8-419d-eceb-4578a222c6a1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic dataset...\n",
            "Synthetic data saved to data/pollution.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af43d7d7"
      },
      "source": [
        "# STEP 3: Model Training\n",
        "# ==============================================================\n",
        "print(\"Training model...\")\n",
        "\n",
        "# Define the model\n",
        "model = RandomForestRegressor(random_state=RANDOM_STATE)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
        "                           cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
        "\n",
        "# Fit GridSearchCV to the scaled training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(best_model, MODEL_PATH)\n",
        "print(f\"Best model saved to {MODEL_PATH}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 0: Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import gradio as gr\n",
        "\n",
        "# STEP 1: Setup paths\n",
        "OUTDIR = \"data\"\n",
        "MODEL_PATH = os.path.join(OUTDIR, \"rf_model.pkl\")\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "# STEP 2: Generate synthetic dataset (if not already available)\n",
        "def generate_synthetic_data(n=1000):\n",
        "    np.random.seed(42)\n",
        "    df = pd.DataFrame({\n",
        "        \"pm25_lag1\": np.random.randint(30, 200, n),\n",
        "        \"pm25_lag24\": np.random.randint(20, 180, n),\n",
        "        \"hour\": np.random.randint(0, 24, n),\n",
        "        \"dayofweek\": np.random.randint(0, 7, n),\n",
        "        \"lat\": 28.5 + np.random.rand(n) * 0.5,\n",
        "        \"lon\": 77.0 + np.random.rand(n) * 0.5\n",
        "    })\n",
        "    df[\"pm25\"] = (\n",
        "        0.6 * df[\"pm25_lag1\"] +\n",
        "        0.3 * df[\"pm25_lag24\"] +\n",
        "        2 * np.sin(df[\"hour\"]/24*2*np.pi) +\n",
        "        np.random.randn(n)*10\n",
        "    )\n",
        "    return df\n",
        "\n",
        "df = generate_synthetic_data(2000)\n",
        "\n",
        "# STEP 3: Train/test split\n",
        "X = df[[\"pm25_lag1\", \"pm25_lag24\", \"hour\", \"dayofweek\", \"lat\", \"lon\"]]\n",
        "y = df[\"pm25\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# STEP 4: Train model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model\n",
        "joblib.dump(model, MODEL_PATH)\n",
        "\n",
        "# STEP 5: Evaluate & save plots\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Plot 1: Prediction vs True\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
        "plt.xlabel(\"True PM2.5\")\n",
        "plt.ylabel(\"Predicted PM2.5\")\n",
        "plt.title(\"Prediction vs True\")\n",
        "plt.savefig(os.path.join(OUTDIR, \"pred_vs_true.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Plot 2: Sensor map (median PM2.5 by location)\n",
        "df_map = df.groupby([\"lat\",\"lon\"])[\"pm25\"].median().reset_index()\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(df_map[\"lon\"], df_map[\"lat\"], c=df_map[\"pm25\"], cmap=\"coolwarm\", s=60)\n",
        "plt.colorbar(label=\"Median PM2.5\")\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.title(\"Sensor Map - Median PM2.5\")\n",
        "plt.savefig(os.path.join(OUTDIR, \"sensor_map_median_pm25.png\"))\n",
        "plt.close()\n",
        "\n",
        "print(\"‚úÖ Model trained & plots saved.\")\n",
        "\n",
        "# STEP 6: Prediction function for Gradio\n",
        "def predict_pollution_gr(pm25_lag1, pm25_lag24, hour, dayofweek, lat, lon):\n",
        "    try:\n",
        "        model = joblib.load(MODEL_PATH)\n",
        "        x = pd.DataFrame([[pm25_lag1, pm25_lag24, hour, dayofweek, lat, lon]],\n",
        "                         columns=[\"pm25_lag1\",\"pm25_lag24\",\"hour\",\"dayofweek\",\"lat\",\"lon\"])\n",
        "        pred = model.predict(x)[0]\n",
        "\n",
        "        img1 = os.path.join(OUTDIR,'pred_vs_true.png')\n",
        "        img2 = os.path.join(OUTDIR,'sensor_map_median_pm25.png')\n",
        "\n",
        "        img1_out = img1 if os.path.exists(img1) else None\n",
        "        img2_out = img2 if os.path.exists(img2) else None\n",
        "\n",
        "        return round(pred,2), img1_out, img2_out\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", None, None\n",
        "\n",
        "# STEP 7: Gradio UI\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## üåç Smart City Pollution Predictor\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            pm25_lag1_in = gr.Number(label=\"PM2.5 (previous hour)\", value=60)\n",
        "            pm25_lag24_in = gr.Number(label=\"PM2.5 (24 hours ago)\", value=50)\n",
        "            hour_in = gr.Slider(0, 23, step=1, label=\"Hour of Day\", value=12)\n",
        "            day_in = gr.Dropdown(list(range(7)), label=\"Day of Week\", value=0)\n",
        "            lat_in = gr.Number(label=\"Latitude\", value=28.6139)\n",
        "            lon_in = gr.Number(label=\"Longitude\", value=77.2090)\n",
        "            btn = gr.Button(\"Predict PM2.5\")\n",
        "\n",
        "        with gr.Column():\n",
        "            out = gr.Number(label=\"Predicted PM2.5\")\n",
        "            img_out1 = gr.Image(label=\"Prediction vs True Plot\")\n",
        "            img_out2 = gr.Image(label=\"Sensor Map Plot\")\n",
        "\n",
        "    btn.click(\n",
        "        predict_pollution_gr,\n",
        "        inputs=[pm25_lag1_in, pm25_lag24_in, hour_in, day_in, lat_in, lon_in],\n",
        "        outputs=[out, img_out1, img_out2]\n",
        "    )\n",
        "\n",
        "    demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "YtN416ciKhgM",
        "outputId": "ee8f9d6d-7dc3-4d16-8c13-5737ab871b9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model trained & plots saved.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f50a45f597787d21d9.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f50a45f597787d21d9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}